# 탐색적 데이터 분석

통계학은 지난 한 세기동안 대부분 발전하였다. `데이터 분석`과 `모델링`을 다루는 일종의 응용과학이다.

통계학의 수학적 기반인 확률론은 17세기에서 19세기를 걸치면서 토머스 베이즈, 피에르시몽 드 라플라스, 카를 가우스가 이룬 업적을 기반으로 발전하였다.

현대 통계학은 1800년대 후반 프랜시스 골턴과 칼 피어슨에서 시작하여 20세기 초 로널드 피셔가 `실험계획법`과 `최대우도추정`를 정리하면서 정립되었다.

`탐색적 데이터 분석(Exploratory data analysis, EDA)`은 비교적 새로운 영역이다. 이전 통계학은 `추론`, 적은 표본에서 더 큰 모집단에 대한 결론을 도출하기 위한 일련의 과정이었지만, 1962년 존 투키가 `데이터 분석의 미래`라는 대표 논문을 통해 통계학의 개혁을 요구하며 `데이터 분석`이라는 새로운 과학적 학문을 제안했다. 탐색적 데이터 분석의 투키의 1977년 동명의 책을 통해 정립되었다.

투키의 학생이었던 데이비드 도노호 스탠퍼드 교수가 투키 탄생 100주년 기념 워크샵에서 발표한 논문([`50 Years of Data Science`](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)]을 읽어보자.

## 정형화된 데이터의 요소

> 데이터 과학에서 가장 중요한 도전은 폭발적인 양의 원시 데이터를 활용가능한 형태의 정보로 변환하는 것이다.

데이터는 다음과 같은 형태로 정리할 수 있다.

* 연속형(continuous)
* 이산(discrete)
* 범주형(categorical)
* 이진(binary)
* 순서형(ordinal)

## 테이블 데이터

데이터 분석에서 대표적으로 사용되는 객체는 테이블 데이터(rectangular data)이다. 관련하여 용어를 정리하면 아래와 같다.

* 데이터 프레임: 통계와 ML에서 가장 기본이 되는 테이블 형태의 데이터 구조
* 피쳐: 일반적으로 테이블의 각 열. 유의어: 특징, 속성, 입력, 예측변수, 변수
* 결과(outcome): 목표가 되는 예측 성과물. 실험이나 연구는 피처를 이용해 결과를 예측한다. 유의어: 종속변수, 응답, 목표, 출력
* 레코드: 일반적으로 테이블의 각 행. 유의어: 사례, 관측값, 샘플

### 데이터 프레임과 인덱스

인덱스는 성능향상을 위해서 사용되는 열인데, 파이썬의 `pandas`에서는 다중/계층적 인덱스를 지원한다.

반면 R에서는 `data.frame`는 인덱스를 갖지만 다중 인덱스를 지원하지 않는다. 이를 보완하기 위해 `data.table`과 `dplyr`가 널리 사용되고 있다.

### 테이블 형식이 아닌 데이터 구조

시계열 데이터는 동일한 변수 안에 연속적인 측정값을 갖는다.

공간 데이터는 객체와 필드(field) 정보를 갖는다.

그래프(혹은 네트워크) 데이터는 객체들 간의 관계에 집중한다. 물류 혹은 추천 시스템에서 유용하게 이용되고 있다.

## 위치 추정

데이터가 주어졌을 때 가장 기초적인 단계는 각 피처의 대푯값(typical value)를 구하는 것이다. 이는 대부분의 값이 어디쯤 위치하는지(중심경향성)를 나타내는 추정값이다. 관련하여 주요 용어를 정리하면 다음과 같다.

* 평균
* 가중평균
* 중간값(median)
* 가중 중간값
* 절사평균(trimmed mean) 혹은 절단평균(truncated mean)
* 로버스트하다(robust): 극단값에 민감하지 않다. 저항성이 있다(resistant).
* 특잇값(outlier)

### 측정지표와 추정값

데이터에서 얻은 값을 실제 상태를 나타내는 이론적 참값과 구분하기 위하여 계산된 값을 추정값(estimate)과 측정지표(metric)로 부른다. 전자는 통계학에서 부르는 용어로 불확실성을 이해하고자 하는 노력의 발로인 반면, 후자는 데이터과학에서 이용되는 용어로 비즈니스나 조직의 목표치에 관심이 있음을 반영한다. 그러므로, 통계학자는 추정하고, 데이터과학자는 측정한다.

### 평균

평균은 가장 기본적인 위치 추정 방법이다. 값의 총합을 값의 개수로 나눈 값이다. 엑스바로 표시한다.

절사평균은 정렬후 양쪽 끝 p개의 값을 제외하고 평균한 것으로 피겨대회에서 채점시 최고점과 최저점을 제외하고 평균내는 방식이다. 이를 통해 극단값의 영향을 제거하고자 한다.

가중평균은 특정값이 큰 변화량을 가질 때, 그 영향을 상쇄시킬 수 있다. 예를 들어, 특정 센서의 정확도가 떨어진다면, 해당 센서의 가중치를 낮출 수 있다. 그리고 샘플 수집시 특정 집단의 비율이 너무 크거나 작을 경우, 가중치를 적용할 수 있다.

### 중간값과 로버스트 추정

데이터를 정렬하여 가장 중간에 위치하는 값을 중간값이라고 정의하는데, 데이터에 특이치가 있는 경우 평균이 왜곡될 수 있다. 흔히 드는 예는 빌게이츠를 포함한 지역의 가구소득이다.

가중중간값은 중간값과 비슷하나, 단순히 가운데 위치한 값이 아니라, 가중치를 적용한 위 어떤 기준에 따라 상위 절반의 합과 하위 절반의 합이 같은 지점을 찾게 된다. 이 역시 특잇값에 로버스트하다.

특잇값이 꼭 틀린 데이터는 아니다. 물론 유닛이 잘못되거나, 센서 오작동 등으로 에러가 특잇값으로 잡히기도 한다. 어떤 경우든 특잇값을 확인하고 자세히 살펴볼 필요가 있다.

`이상검출(anomaly detection)`은 특이치에 관심을 두는 분야이다.

중간값만이 유일한 로버스트한 방법은 아니다. 절사평균은 중간값과 평균의 절충안이라고 생각할 수 있다.

통계학자들은 로버스트하면서 효율적인 추정법을 찾기 위해 노력해 왔으나, 이는 작은 데이터에 유용하게 사용되었다. 하지만 빅데이터 시대에 큰 이점이 있다고 보기는 어렵다.

### 더 읽을거리

* 퍼듀대학교의 마이클 레빈의 [`[강의 슬라이드]`](http:/bit.ly/2NDvrhs)
* 존 투키의 고전 `탐색적 데이터 분석`은 여전히 널리 읽힌다.

