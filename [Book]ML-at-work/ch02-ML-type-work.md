# 머신러닝으로 할 수 있는 일

## 머신러닝 알고리즘 선택 방법

* 분류
* 회귀
* 군집화
* 차원 축소
* 그 외
  * 추천
  * 이상 탐지
  * 고빈도 패턴 마이닝
  * 강화 학습

사이킷런 튜토리얼에서는 [모델 선택을 위한 플로우 차트](http://scikit-learn.org/stable/tutorial/machine_learning_map/)를 제공하고 있다.

학습에 사용되는 데이터 수, 연속/비연속, 정답 레이블 존재유무 등이 핵심요소이다. 특히 데이터 수가 너무 많을 때는 온라인 학습 알고리즘을 이용할 수 있다.

### 사이킷런이 제공하는 온라인 학습 알고리즘

사이킷런은 분류용으로 `SGDClassifier`와 회귀용 `SGDRegressor`를 제공한다. 손실함수와 규제항에 따라 SVM, 로지스틱 회귀, SVR과 비슷한 성능을 보여준다. 온라인 학습이 가능한 선형 분리기로는 Passive Agressive 알고리즘을 제공하지만, SCW나 AROW와 같은 비교적 최신 알고리즘은 제공하지 않는다. `0.18.0`부터 신경망용 ADAM 구현이 추가되었으며, `MLPClassifier` 클래스에서 이용할 수 있다.

## 분류

살펴볼 분류 알고리즘은 다음과 같다.

* 퍼셉트론
* 로지스틱 회귀
* 서포트 벡터 머신
* 신경망
* k-최근접 이웃(k-NN)
* 결정 트리
* 랜덤 포레스트
* 경사 부스팅 결정 트리(GBDT)

퍼셉트론, 로지스틱 회귀, SVM, 신경망은 두 클래스의 경계면에 대한 함수를 학습한다. 경계면 함수란 두 클래스를 구분하는 초평면을 이야기하며, 결정 경계(Decision Boundary)라고도 한다. k-NN은 거리를 기준으로 판단하며, 나머지 셋은 트리 구조로 규칙집합을 학습한다.

이외에도 텍스트 분류에 많이 사용되는 나이브 베이즈나 음성인식에 오랫동안 사용된 은닉 마르코프 모델(HMM) 등도 있다. 이들 알고리즘은 데이터에 잠재된 확률분포를 추정하는 방법으로 모델링한다.
