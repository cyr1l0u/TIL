# 케라스 오픈 챗에서 유용한 자료

## 이명규씨 (2019.02.22)

역시 SOTA논문이 괜히 SOTA가 아닌가봐요 ㅠㅠ

이것저것 테스트해보면서 느낀 바는 논문이나 Keras가 제공하는 디폴트값은 괜히 디폴트가 아니다라는것...

* [Making Classification Competitive for Deep Metric Learning](https://arxiv.org/abs/1811.12649)
* [Batch Feature Erasing for Person Re-identification and Beyond](https://arxiv.org/abs/1811.07130)
* [Attention-based Ensemble for Deep Metric Learning](https://arxiv.org/abs/1804.00382)
* [Total Recall: Automatic Query Expansion with a Generative Feature Model for Object Retrieval](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/iccv2007.pdf)
* [Total Recall II: Query Expansion Revisited](http://cmp.felk.cvut.cz/~chum/papers/chum_cvpr11.pdf)

## 이진원 (2019.02.25)

* [Somethings about TPU](https://drive.google.com/file/d/1yEA4l-IIdTykPy3Flp7F6ZySUEU39Amv/view)
